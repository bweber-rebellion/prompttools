{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d8e180d",
   "metadata": {},
   "source": [
    "# Human Feedback Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f7e44e",
   "metadata": {},
   "source": [
    "If you want to view this example in Google Colab, see [here](https://colab.research.google.com/github/hegelai/prompttools/blob/main/examples/notebooks/HumanFeedback.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08def965",
   "metadata": {},
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8821b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --quiet --force-reinstall prompttools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d598292",
   "metadata": {},
   "source": [
    "## Setup imports and API keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d899afc2",
   "metadata": {},
   "source": [
    "First, we'll need to set our API keys. If we are in DEBUG mode, we don't need to use a real OpenAI key, so for now we'll set them to empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "623cdd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DEBUG\"] = \"1\"  # Set to \"1\" if you want to use debug mode.\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842f1e47",
   "metadata": {},
   "source": [
    "Then we'll import the relevant `prompttools` modules to setup our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dadc080f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompttools.harness import PromptTemplateExperimentationHarness\n",
    "from prompttools.experiment import OpenAICompletionExperiment\n",
    "from prompttools.selector.prompt_selector import PromptSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622dea9a",
   "metadata": {},
   "source": [
    "## Run experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3babfe5a",
   "metadata": {},
   "source": [
    "Next, we create our test inputs. For this example, we'll use a prompt template, which uses [jinja](https://jinja.palletsprojects.com/en/3.1.x/) for templating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d878c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = [\n",
    "    \"\"\"\n",
    "Answer the following question. \n",
    "If it is not prime, give its decomposition.\n",
    "\"\"\",\n",
    "    \"\"\"\n",
    "Answer the following question.\n",
    "\"\"\",\n",
    "]\n",
    "\n",
    "inputs = [{\"input\": \"is 17077 a prime number\"}, {\"input\": \"Is 17077 prime?\"}]\n",
    "\n",
    "selectors = [PromptSelector(instructions[i], inputs[j]) for i in range(len(instructions)) for j in range(len(inputs))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273e9908",
   "metadata": {},
   "source": [
    "Now we can define an experimentation harness for our inputs and model. We could also pass model arguments if, for example, we wanted to change the model temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f16f1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = OpenAICompletionExperiment([\"text-davinci-003\"], selectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fa5450",
   "metadata": {},
   "source": [
    "We can then run the experiment to get results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "866009ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response(s)</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nAnswer the following question. \\nIf it is not prime, give its decomposition.</td>\n",
       "      <td>{\"text\": \"George Washington\"}</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nAnswer the following question. \\nIf it is not prime, give its decomposition.</td>\n",
       "      <td>{\"text\": \"George Washington\"}</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nAnswer the following question.</td>\n",
       "      <td>{\"text\": \"George Washington\"}</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nAnswer the following question.</td>\n",
       "      <td>{\"text\": \"George Washington\"}</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           prompt  \\\n",
       "0  \\nAnswer the following question. \\nIf it is not prime, give its decomposition.   \n",
       "1  \\nAnswer the following question. \\nIf it is not prime, give its decomposition.   \n",
       "2  \\nAnswer the following question.                                                 \n",
       "3  \\nAnswer the following question.                                                 \n",
       "\n",
       "                     response(s)   latency  \n",
       "0  {\"text\": \"George Washington\"}  0.000019  \n",
       "1  {\"text\": \"George Washington\"}  0.000011  \n",
       "2  {\"text\": \"George Washington\"}  0.000008  \n",
       "3  {\"text\": \"George Washington\"}  0.000007  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment.run()\n",
    "experiment.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9c5ef5",
   "metadata": {},
   "source": [
    "You can use the `pivot` keyword argument to view results by the template and inputs that created them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "395c5710",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# harness.visualize(pivot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1abc866",
   "metadata": {},
   "source": [
    "## Evaluate with human feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a9900e",
   "metadata": {},
   "source": [
    "As an alternative to systematic evalaution, prompttools supports gathering human feedback directly in notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3defecd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Experiment.gather_feedback() missing 2 required positional arguments: 'pivot_data' and 'pivot_columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather_feedback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Experiment.gather_feedback() missing 2 required positional arguments: 'pivot_data' and 'pivot_columns'"
     ]
    }
   ],
   "source": [
    "experiment.gather_feedback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc46550",
   "metadata": {},
   "outputs": [],
   "source": [
    "harness.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c2fa6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
